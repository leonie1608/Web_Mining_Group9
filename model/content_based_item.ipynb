{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "129931f3-a0b8-4e73-8c52-f4674df4344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the surprise package\n",
    "!pip install -q -U scikit-surprise\n",
    "from surprise import Dataset, Reader\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import KNNWithMeans\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import KNNBasic\n",
    "from surprise import SVD\n",
    "import random\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "23042ac9-73b8-4622-8d97-051c1ccf5ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.expanduser('~/Documents/Studium/Master/Web Mining/Project/data_kindle_preprocessed.xlsx')\n",
    "data_preprocessed = pd.read_excel(path, index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "556f35bc-1925-42f4-8609-aab1e3eaad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_preprocessed.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9b3b7c9f-7809-4faf-800b-a317d3202cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace non-finite values with NaN\n",
    "data['publication_year'] = data['publication_year'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Convert NaN to a placeholder value (e.g., -1)\n",
    "data['publication_year'].fillna(-1, inplace=True)\n",
    "\n",
    "# Convert the column to integers\n",
    "data['publication_year'] = data['publication_year'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f8ef5d58-f199-443b-855c-1c67a6112996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>brand</th>\n",
       "      <th>language</th>\n",
       "      <th>print_length_category</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>category_string</th>\n",
       "      <th>paid_free</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>A3OC8ZG1S3OAVA</td>\n",
       "      <td>B0015Z7VFQ</td>\n",
       "      <td>Look What Santa Brought (The Perfect Gift) - K...</td>\n",
       "      <td>Visit Amazon's Annmarie McKenna Page</td>\n",
       "      <td>English</td>\n",
       "      <td>small</td>\n",
       "      <td>2009</td>\n",
       "      <td>Kindle Store, Kindle eBooks, Literature &amp; Fiction</td>\n",
       "      <td>Paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>A2U8YWPP1PYHJM</td>\n",
       "      <td>B0017HNV1U</td>\n",
       "      <td>Babylonian Laws- The Oldest Code of Laws in th...</td>\n",
       "      <td>King of Babylon Hammurabi</td>\n",
       "      <td>English</td>\n",
       "      <td>small</td>\n",
       "      <td>2008</td>\n",
       "      <td>Kindle Store, Kindle eBooks, History</td>\n",
       "      <td>Paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>A3361XGKYF17S3</td>\n",
       "      <td>B001892EI8</td>\n",
       "      <td>The Billionaire&amp;s Baby (Harlequin Mini # 19) -...</td>\n",
       "      <td>Leanne Banks</td>\n",
       "      <td>English</td>\n",
       "      <td>small</td>\n",
       "      <td>2008</td>\n",
       "      <td>Kindle Store, Kindle eBooks, Romance</td>\n",
       "      <td>Paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>AVGYENZU56KBR</td>\n",
       "      <td>B001892EI8</td>\n",
       "      <td>The Billionaire&amp;s Baby (Harlequin Mini # 19) -...</td>\n",
       "      <td>Leanne Banks</td>\n",
       "      <td>English</td>\n",
       "      <td>small</td>\n",
       "      <td>2008</td>\n",
       "      <td>Kindle Store, Kindle eBooks, Romance</td>\n",
       "      <td>Paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>A3361XGKYF17S3</td>\n",
       "      <td>B001892DGG</td>\n",
       "      <td>The Wallflower (Halle Puma Book 1) - Kindle ed...</td>\n",
       "      <td>Visit Amazon's Dana Marie Bell Page</td>\n",
       "      <td>English</td>\n",
       "      <td>small</td>\n",
       "      <td>2008</td>\n",
       "      <td>Kindle Store, Kindle eBooks, Romance</td>\n",
       "      <td>Paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19566</th>\n",
       "      <td>4.0</td>\n",
       "      <td>A1EQY74OFGE4NE</td>\n",
       "      <td>B01HIGNUGE</td>\n",
       "      <td>Final Jackpot - Kindle edition</td>\n",
       "      <td>Visit Amazon's Parker Avrile Page</td>\n",
       "      <td>English</td>\n",
       "      <td>small</td>\n",
       "      <td>2016</td>\n",
       "      <td>Kindle Store, Kindle eBooks, Literature &amp; Fiction</td>\n",
       "      <td>Paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19567</th>\n",
       "      <td>3.0</td>\n",
       "      <td>A1EQY74OFGE4NE</td>\n",
       "      <td>B01HINH1WQ</td>\n",
       "      <td>Claimed</td>\n",
       "      <td>Visit Amazon's Wolf Specter Page</td>\n",
       "      <td>English</td>\n",
       "      <td>medium</td>\n",
       "      <td>2016</td>\n",
       "      <td>Kindle Store, Kindle eBooks, Literature &amp; Fiction</td>\n",
       "      <td>Paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19568</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A1SVA69J57MX2A</td>\n",
       "      <td>B01HIOR0S0</td>\n",
       "      <td>Battle Beyond Earth</td>\n",
       "      <td>Visit Amazon's Nick S. Thomas Page</td>\n",
       "      <td>English</td>\n",
       "      <td>small</td>\n",
       "      <td>2016</td>\n",
       "      <td>Kindle Store, Kindle eBooks, Science Fiction &amp;...</td>\n",
       "      <td>Paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19569</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A3FVMG7SWNF7QR</td>\n",
       "      <td>B01HIULQXY</td>\n",
       "      <td>Clarity&amp;s Doom (Ancient Origins Book 1) - Kind...</td>\n",
       "      <td>Visit Amazon's C.L. Scholey Page</td>\n",
       "      <td>English</td>\n",
       "      <td>small</td>\n",
       "      <td>2016</td>\n",
       "      <td>Kindle Store, Kindle eBooks, Literature &amp; Fiction</td>\n",
       "      <td>Paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19570</th>\n",
       "      <td>4.0</td>\n",
       "      <td>A2DD8D4Y1UMJ2C</td>\n",
       "      <td>B01HJ628HU</td>\n",
       "      <td>Sworn To War (Courtlight Book 9) eBook</td>\n",
       "      <td>Visit Amazon's Terah Edun Page</td>\n",
       "      <td>English</td>\n",
       "      <td>small</td>\n",
       "      <td>2016</td>\n",
       "      <td>Kindle Store, Kindle eBooks, Teen &amp; Young Adult</td>\n",
       "      <td>Paid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19571 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rating      reviewerID        asin  \\\n",
       "0         1.0  A3OC8ZG1S3OAVA  B0015Z7VFQ   \n",
       "1         4.0  A2U8YWPP1PYHJM  B0017HNV1U   \n",
       "2         3.0  A3361XGKYF17S3  B001892EI8   \n",
       "3         4.0   AVGYENZU56KBR  B001892EI8   \n",
       "4         3.0  A3361XGKYF17S3  B001892DGG   \n",
       "...       ...             ...         ...   \n",
       "19566     4.0  A1EQY74OFGE4NE  B01HIGNUGE   \n",
       "19567     3.0  A1EQY74OFGE4NE  B01HINH1WQ   \n",
       "19568     5.0  A1SVA69J57MX2A  B01HIOR0S0   \n",
       "19569     5.0  A3FVMG7SWNF7QR  B01HIULQXY   \n",
       "19570     4.0  A2DD8D4Y1UMJ2C  B01HJ628HU   \n",
       "\n",
       "                                                   title  \\\n",
       "0      Look What Santa Brought (The Perfect Gift) - K...   \n",
       "1      Babylonian Laws- The Oldest Code of Laws in th...   \n",
       "2      The Billionaire&s Baby (Harlequin Mini # 19) -...   \n",
       "3      The Billionaire&s Baby (Harlequin Mini # 19) -...   \n",
       "4      The Wallflower (Halle Puma Book 1) - Kindle ed...   \n",
       "...                                                  ...   \n",
       "19566                     Final Jackpot - Kindle edition   \n",
       "19567                                            Claimed   \n",
       "19568                                Battle Beyond Earth   \n",
       "19569  Clarity&s Doom (Ancient Origins Book 1) - Kind...   \n",
       "19570             Sworn To War (Courtlight Book 9) eBook   \n",
       "\n",
       "                                      brand language print_length_category  \\\n",
       "0      Visit Amazon's Annmarie McKenna Page  English                 small   \n",
       "1                 King of Babylon Hammurabi  English                 small   \n",
       "2                              Leanne Banks  English                 small   \n",
       "3                              Leanne Banks  English                 small   \n",
       "4       Visit Amazon's Dana Marie Bell Page  English                 small   \n",
       "...                                     ...      ...                   ...   \n",
       "19566     Visit Amazon's Parker Avrile Page  English                 small   \n",
       "19567      Visit Amazon's Wolf Specter Page  English                medium   \n",
       "19568    Visit Amazon's Nick S. Thomas Page  English                 small   \n",
       "19569      Visit Amazon's C.L. Scholey Page  English                 small   \n",
       "19570        Visit Amazon's Terah Edun Page  English                 small   \n",
       "\n",
       "      publication_year                                    category_string  \\\n",
       "0                 2009  Kindle Store, Kindle eBooks, Literature & Fiction   \n",
       "1                 2008               Kindle Store, Kindle eBooks, History   \n",
       "2                 2008               Kindle Store, Kindle eBooks, Romance   \n",
       "3                 2008               Kindle Store, Kindle eBooks, Romance   \n",
       "4                 2008               Kindle Store, Kindle eBooks, Romance   \n",
       "...                ...                                                ...   \n",
       "19566             2016  Kindle Store, Kindle eBooks, Literature & Fiction   \n",
       "19567             2016  Kindle Store, Kindle eBooks, Literature & Fiction   \n",
       "19568             2016  Kindle Store, Kindle eBooks, Science Fiction &...   \n",
       "19569             2016  Kindle Store, Kindle eBooks, Literature & Fiction   \n",
       "19570             2016    Kindle Store, Kindle eBooks, Teen & Young Adult   \n",
       "\n",
       "      paid_free  \n",
       "0          Paid  \n",
       "1          Paid  \n",
       "2          Paid  \n",
       "3          Paid  \n",
       "4          Paid  \n",
       "...         ...  \n",
       "19566      Paid  \n",
       "19567      Paid  \n",
       "19568      Paid  \n",
       "19569      Paid  \n",
       "19570      Paid  \n",
       "\n",
       "[19571 rows x 10 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6bd10f71-bff5-46db-a267-c75a0b9dd1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>book_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0015Z7VFQ</td>\n",
       "      <td>Look What Santa Brought (The Perfect Gift) - K...</td>\n",
       "      <td>Kindle Store, Kindle eBooks, Literature &amp; Fict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B0017HNV1U</td>\n",
       "      <td>Babylonian Laws- The Oldest Code of Laws in th...</td>\n",
       "      <td>Kindle Store, Kindle eBooks, History  King of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B001892EI8</td>\n",
       "      <td>The Billionaire&amp;s Baby (Harlequin Mini # 19) -...</td>\n",
       "      <td>Kindle Store, Kindle eBooks, Romance  Leanne B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B001892DGG</td>\n",
       "      <td>The Wallflower (Halle Puma Book 1) - Kindle ed...</td>\n",
       "      <td>Kindle Store, Kindle eBooks, Romance  Visit Am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B001BRD238</td>\n",
       "      <td>Secrets: a PsyCop Novel - Kindle edition</td>\n",
       "      <td>Kindle Store, Kindle eBooks, Romance  Visit Am...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin                                              title  \\\n",
       "0  B0015Z7VFQ  Look What Santa Brought (The Perfect Gift) - K...   \n",
       "1  B0017HNV1U  Babylonian Laws- The Oldest Code of Laws in th...   \n",
       "2  B001892EI8  The Billionaire&s Baby (Harlequin Mini # 19) -...   \n",
       "4  B001892DGG  The Wallflower (Halle Puma Book 1) - Kindle ed...   \n",
       "5  B001BRD238           Secrets: a PsyCop Novel - Kindle edition   \n",
       "\n",
       "                                           book_info  \n",
       "0  Kindle Store, Kindle eBooks, Literature & Fict...  \n",
       "1  Kindle Store, Kindle eBooks, History  King of ...  \n",
       "2  Kindle Store, Kindle eBooks, Romance  Leanne B...  \n",
       "4  Kindle Store, Kindle eBooks, Romance  Visit Am...  \n",
       "5  Kindle Store, Kindle eBooks, Romance  Visit Am...  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"book_info\"] =  data['category_string'] + '  ' + data['brand'] + '  ' + data['paid_free']+ ' ' + data['print_length_category'] + ' ' + data['publication_year'] + '  ' + data['language'] \n",
    "data.drop(['rating', 'brand', 'reviewerID', 'language','print_length_category', 'publication_year', 'category_string', 'paid_free'],axis=1,inplace=True)\n",
    "data.drop_duplicates(subset=['asin', 'title'], inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ee96181d-3c6e-4c3a-8fa6-149d64b82fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape: (8700, 3)\n",
      "Validation Data Shape: (2900, 3)\n",
      "Test Data Shape: (2901, 3)\n",
      "Cosine similarity matrix size (Train): (8700, 8700)\n",
      "Cosine similarity matrix size (Validation): (2900, 8700)\n",
      "Cosine similarity matrix size (Test): (2901, 8700)\n",
      "Validation MAE: 1.0882758620689654\n",
      "Validation RMSE: 1.3721365167830988\n",
      "Test MAE: 1.0827300930713548\n",
      "Test RMSE: 1.3517769530190797\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Vectorize the text data using TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1, 2), min_df=1, stop_words='english')\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data['book_info'])\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.25, random_state=42)\n",
    "\n",
    "# Debugging print\n",
    "print(\"Train Data Shape:\", train_data.shape)\n",
    "print(\"Validation Data Shape:\", val_data.shape)\n",
    "print(\"Test Data Shape:\", test_data.shape)\n",
    "\n",
    "# Calculate cosine similarity matrices\n",
    "tfidf_matrix_train = tfidf_vectorizer.transform(train_data['book_info'])\n",
    "tfidf_matrix_val = tfidf_vectorizer.transform(val_data['book_info'])\n",
    "tfidf_matrix_test = tfidf_vectorizer.transform(test_data['book_info'])\n",
    "\n",
    "# Calculate cosine similarity matrices with correct dimensions\n",
    "cosine_sim_train = cosine_similarity(tfidf_matrix_train, tfidf_matrix_train)\n",
    "cosine_sim_val = cosine_similarity(tfidf_matrix_val, tfidf_matrix_train)\n",
    "cosine_sim_test = cosine_similarity(tfidf_matrix_test, tfidf_matrix_train)\n",
    "\n",
    "# Debugging print\n",
    "print(\"Cosine similarity matrix size (Train):\", cosine_sim_train.shape)\n",
    "print(\"Cosine similarity matrix size (Validation):\", cosine_sim_val.shape)\n",
    "print(\"Cosine similarity matrix size (Test):\", cosine_sim_test.shape)\n",
    "\n",
    "# Implement function to recommend books\n",
    "def recommend(title, cosine_sim_matrix, train_data):\n",
    "    indices = train_data[train_data['title'] == title].index.tolist()\n",
    "    if not indices:\n",
    "        return []\n",
    "    \n",
    "    recommended_books = []\n",
    "    for idx in indices:\n",
    "        try:\n",
    "            sim_scores = list(enumerate(cosine_sim_matrix[idx]))\n",
    "            sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "            sim_scores = sim_scores[1:11]  # Top 10 similar items\n",
    "            book_indices = [i[0] for i in sim_scores]\n",
    "            recommended_books.extend(train_data['title'].iloc[book_indices].tolist())\n",
    "        except IndexError:\n",
    "            continue\n",
    "    \n",
    "    return recommended_books if recommended_books else []  # Return empty list if no recommendations found\n",
    "\n",
    "# Pre-calculate recommendations for all books where recommendations are available\n",
    "all_titles = train_data['title'].unique()\n",
    "pred_content_based_recommender_system = {title: recommend(title, cosine_sim_train, train_data)[:10] for title in all_titles}\n",
    "\n",
    "# Evaluate the recommender system\n",
    "def evaluate_recommender(test_data, cosine_sim_matrix, train_data):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for title in test_data['title']:\n",
    "        true_books = set(test_data[test_data['title'] == title]['title'])\n",
    "        recommended_books = set(pred_content_based_recommender_system.get(title, []))  # Get precalculated recommendations\n",
    "        y_true.append(len(true_books))\n",
    "        y_pred.append(len(recommended_books))\n",
    "\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    return mae, rmse\n",
    "\n",
    "# Evaluate the recommender system\n",
    "mae_val, rmse_val = evaluate_recommender(val_data, cosine_sim_val, train_data)\n",
    "mae_test, rmse_test = evaluate_recommender(test_data, cosine_sim_test, train_data)\n",
    "\n",
    "print(\"Validation MAE:\", mae_val)\n",
    "print(\"Validation RMSE:\", rmse_val)\n",
    "print(\"Test MAE:\", mae_test)\n",
    "print(\"Test RMSE:\", rmse_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1250185d-79c1-4b0c-a8c3-d2e996cacfc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Spark (Ruin Outlaws MC series Book 2) - Kindle edition',\n",
       " 'Candy Man - Kindle edition',\n",
       " 'Christmas with the Billionaire (Holiday Encounters Book 1) - Kindle edition',\n",
       " ' Make-Believe Wife (Destiny Bay Romances',\n",
       " 'The Apprenticeship of Julian St. Albans (Consulting Magic Book 2) - Kindle edition',\n",
       " 'Turkey in the Snow - Kindle edition',\n",
       " 'Puppy, Car, and Snow - Kindle edition',\n",
       " 'A Brand New Step: A Taboo Short (Sexy Household Secrets: Man of the House Book 2) - Kindle edition',\n",
       " 'Bitter Taffy (Candy Man Book 2) - Kindle edition',\n",
       " 'Getting Lucky with the Rock Star (Holiday Encounters Book 3) - Kindle edition']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_content_based_recommender_system.get('Second Touch (Emma&s Arabian Nights, #2) - Kindle edition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b9e03a9c-da2e-420c-b282-a05459d0d0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.0190001  0.02312506 ... 0.04199093 0.0742936  0.03085186]\n",
      " [0.0190001  1.         0.26348392 ... 0.02212988 0.02601486 0.01829713]\n",
      " [0.02312506 0.26348392 1.         ... 0.02693433 0.03166275 0.02226948]\n",
      " ...\n",
      " [0.04199093 0.02212988 0.02693433 ... 1.         0.1441296  0.09686777]\n",
      " [0.0742936  0.02601486 0.03166275 ... 0.1441296  1.         0.11387327]\n",
      " [0.03085186 0.01829713 0.02226948 ... 0.09686777 0.11387327 1.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Big Rock (Big Rock Book 1) - Kindle edition',\n",
       " 'First Night: (Seductive Nights: Julia and Clay Book #0.5) - Kindle edition',\n",
       " 'Every Second With You (No Regrets Book 2) - Kindle edition',\n",
       " 'Caught Up in Her (Caught Up in Love) - Kindle edition',\n",
       " 'The Start of Us (No Regrets) - Kindle edition',\n",
       " 'Sinful Nights Bundle: Books 1-3 - Kindle edition',\n",
       " 'Tempted By A Rogue - Kindle edition',\n",
       " 'Blurred Lines (Love Unexpectedly) - Kindle edition',\n",
       " 'Surviving For Us - Kindle edition',\n",
       " 'ARENA (An Artemus Newton Thriller Book 2) - Kindle edition']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorizing the book info column using TFidf Vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "tf = TfidfVectorizer(analyzer=\"word\", ngram_range=(1,2), min_df=1, stop_words='english')\n",
    "\n",
    "tfidf_matrix = tf.fit_transform(data['book_info'])\n",
    "\n",
    "cosine_sim =  cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "print(cosine_sim)\n",
    "\n",
    "indices = pd.Series(data['title'])\n",
    "indices[:5]\n",
    "\n",
    "def recommend(title, cosine_sim = cosine_sim):\n",
    "    if title not in indices.values:\n",
    "        return \"Title not found in the database.\"\n",
    "    recommended_books = []\n",
    "    idx = indices[indices == title].index[0]   # to get the index of book name matching the input book_name\n",
    "    score_series = pd.Series(cosine_sim[idx]).sort_values(ascending = False)   # similarity scores in descending order\n",
    "    top_10_indices = list(score_series.iloc[1:11].index)   # to get the indices of top 10 most similar books\n",
    "    # [1:11] to exclude 0 (index 0 is the input book itself)\n",
    "    \n",
    "    for i in top_10_indices:   # to append the titles of top 10 similar booksto the recommended_books list\n",
    "        recommended_books.append(list(data['title'])[i])\n",
    "        \n",
    "    return recommended_books\n",
    "\n",
    "\n",
    "#to output the recommendations.\n",
    "recommend('Reagan&s Revenge and Ending Emily&s Engagement (The Reed Brothers Series) - Kindle edition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "82930966-5d65-4a08-aeb2-b648836268b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'combined'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'combined'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Content Similarity\u001b[39;00m\n\u001b[0;32m      9\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer()\n\u001b[1;32m---> 10\u001b[0m matrix \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcombined\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     11\u001b[0m cosine_similarities \u001b[38;5;241m=\u001b[39m linear_kernel(matrix, matrix)\n\u001b[0;32m     13\u001b[0m indices \u001b[38;5;241m=\u001b[39m train_data\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreviewerID\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mtolist())\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'combined'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Split data into train, validate, and test sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "# Content Similarity\n",
    "vectorizer = TfidfVectorizer()\n",
    "matrix = vectorizer.fit_transform(train_data[\"combined\"])\n",
    "cosine_similarities = linear_kernel(matrix, matrix)\n",
    "\n",
    "indices = train_data.groupby('reviewerID').apply(lambda x: x.index.tolist())\n",
    "indices = pd.Series(indices, index=indices.index)\n",
    "\n",
    "#print(indices.head())\n",
    "\n",
    "def content_recommender(reviewerID, train_data, vectorizer, cosine_similarities, indices):\n",
    "    if reviewerID in indices:\n",
    "        idx_list = indices[reviewerID]\n",
    "        valid_indices = [idx for idx in idx_list if idx < cosine_similarities.shape[0]]\n",
    "        sim_scores = []\n",
    "        for idx in valid_indices:\n",
    "            sim_scores.extend(enumerate(cosine_similarities[idx]))\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "        sim_scores = sim_scores[1:31]  # Top 30 similar books\n",
    "        book_indices = [i[0] for i in sim_scores]\n",
    "        return train_data.iloc[book_indices]\n",
    "    else:\n",
    "        print(f\"ReviewerID {reviewerID} not found in the training data.\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "reviewerID = 'AVGYENZU56KBR'\n",
    "recommended_books = content_recommender(reviewerID, train_data, vectorizer, cosine_similarities, indices)\n",
    "if recommended_books is not None:\n",
    "    print(recommended_books[['asin', 'combined']])\n",
    "else:\n",
    "    print(\"No recommendations available.\")\n",
    "\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "val_matrix = vectorizer.transform(val_data[\"combined\"])\n",
    "val_cosine_similarities = linear_kernel(val_matrix, matrix)\n",
    "\n",
    "def predict_ratings(reviewerID, data, vectorizer, cosine_similarities):\n",
    "    if reviewerID in indices:\n",
    "        idx_list = indices[reviewerID]\n",
    "        valid_indices = [idx for idx in idx_list if idx < cosine_similarities.shape[0]]\n",
    "        sim_scores = [(i, cosine_similarities[i]) for i in valid_indices]\n",
    "        \n",
    "        print(\"sim_scores before sorting:\", sim_scores)  # Add this line for debugging\n",
    "        \n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "        sim_scores = sim_scores[1:31]  # Top 30 similar books\n",
    "        book_indices = [i[0] for i in sim_scores]\n",
    "        selected_books = data.iloc[book_indices]\n",
    "        return selected_books\n",
    "    else:\n",
    "        print(f\"ReviewerID {reviewerID} not found in the training data.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def evaluate(reviewerID, data, vectorizer, cosine_similarities):\n",
    "    predicted_books = predict_ratings(reviewerID, val_data, vectorizer, val_cosine_similarities)\n",
    "    true_ratings = val_data[val_data['reviewerID'] == reviewerID]['rating']\n",
    "    predicted_ratings = predicted_books['rating']\n",
    "    mae = mean_absolute_error(true_ratings, predicted_ratings)\n",
    "    rmse = mean_squared_error(true_ratings, predicted_ratings, squared=False)\n",
    "    return mae, rmse\n",
    "\n",
    "# Example usage:\n",
    "mae, rmse = evaluate(reviewerID, val_data, vectorizer, val_cosine_similarities)\n",
    "print(f'MAE: {mae}, RMSE: {rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a44afb2-5895-4255-9dbd-7df383c919e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'combined'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'combined'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Content Similarity\u001b[39;00m\n\u001b[0;32m      9\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer()\n\u001b[1;32m---> 10\u001b[0m matrix \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcombined\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     11\u001b[0m cosine_similarities \u001b[38;5;241m=\u001b[39m linear_kernel(matrix, matrix)\n\u001b[0;32m     13\u001b[0m indices \u001b[38;5;241m=\u001b[39m train_data\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreviewerID\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mtolist())\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'combined'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Split data into train, validate, and test sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "# Content Similarity\n",
    "vectorizer = TfidfVectorizer()\n",
    "matrix = vectorizer.fit_transform(train_data[\"combined\"])\n",
    "cosine_similarities = linear_kernel(matrix, matrix)\n",
    "\n",
    "indices = train_data.groupby('reviewerID').apply(lambda x: x.index.tolist())\n",
    "indices = pd.Series(indices, index=indices.index)\n",
    "\n",
    "#print(indices.head())\n",
    "\n",
    "def content_recommender(train_data, vectorizer, cosine_similarities, indices):\n",
    "    if reviewerID in indices:\n",
    "        idx_list = indices[reviewerID]\n",
    "        valid_indices = [idx for idx in idx_list if idx < cosine_similarities.shape[0]]\n",
    "        sim_scores = []\n",
    "        for idx in valid_indices:\n",
    "            sim_scores.extend(enumerate(cosine_similarities[idx]))\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "        sim_scores = sim_scores[1:31]  # Top 10 similar books\n",
    "        book_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "        print('train_data.iloc[book_indices]')\n",
    "        print(train_data.iloc[book_indices])\n",
    "\n",
    "        \n",
    "        return train_data.iloc[book_indices]\n",
    "    else:\n",
    "        print(f\"ReviewerID {reviewerID} not found in the training data.\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "reviewerID = 'AVGYENZU56KBR'\n",
    "recommended_books = content_recommender(reviewerID, train_data, vectorizer, cosine_similarities, indices)\n",
    "if recommended_books is not None:\n",
    "    print(recommended_books[['asin', 'combined']])\n",
    "else:\n",
    "    print(\"No recommendations available.\")\n",
    "\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "val_matrix = vectorizer.transform(val_data[\"combined\"])\n",
    "val_cosine_similarities = linear_kernel(val_matrix, matrix)\n",
    "\n",
    "def predict_ratings(reviewerID, data, vectorizer, cosine_similarities):\n",
    "\n",
    "    print(\"Shape of cosine_similarities:\", cosine_similarities.shape)  # Add this line for debugging   \n",
    "\n",
    "    \n",
    "    if reviewerID in indices:\n",
    "        idx_list = indices[reviewerID]\n",
    "        valid_indices = [idx for idx in idx_list if idx < cosine_similarities.shape[0]]\n",
    "        sim_scores = [(i, cosine_similarities[i]) for i in valid_indices]\n",
    "        \n",
    "        print(\"sim_scores before sorting:\", sim_scores)  # debugging\n",
    "\n",
    "        print(\"Shape of cosine_similarities:\", cosine_similarities.shape)  # Add this line for debugging\n",
    "\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1][0], reverse=True)\n",
    "\n",
    "        print(\"sim_scores after sorting:\", sim_scores)  # Add this line for debugging\n",
    "\n",
    "        sim_scores = sim_scores[1:31]  # Top 10 similar books\n",
    "        book_indices = [i[0] for i in sim_scores]\n",
    "        selected_books = data.iloc[book_indices]\n",
    "\n",
    "        print(\"Top similar books and their indices:\")\n",
    "        for idx, score in sim_scores[:10]:\n",
    "            print(\"Index:\", idx, \"Score:\", score)\n",
    "\n",
    "        print('selected_books')\n",
    "        print(selected_books)\n",
    "        \n",
    "        return selected_books\n",
    "    else:\n",
    "        print(f\"ReviewerID {reviewerID} not found in the training data.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(reviewerID, data, vectorizer, cosine_similarities):\n",
    "    predicted_books = predict_ratings(reviewerID, train_data, vectorizer, cosine_similarities)\n",
    "    true_ratings = val_data[val_data['reviewerID'] == reviewerID]['rating']\n",
    "    predicted_ratings = predicted_books['rating']\n",
    "    print(\"Length of true_ratings:\", len(true_ratings))\n",
    "    print(\"Length of predicted_ratings:\", len(predicted_ratings))\n",
    "    print(\"True ratings:\", true_ratings)\n",
    "    print(\"Present in the predicted ratings:\", predicted_ratings)\n",
    "    mae = mean_absolute_error(true_ratings, predicted_ratings)\n",
    "    rmse = mean_squared_error(true_ratings, predicted_ratings, squared=False)\n",
    "    return mae, rmse\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "mae, rmse = evaluate(reviewerID, val_data, vectorizer, val_cosine_similarities)\n",
    "print(f'MAE: {mae}, RMSE: {rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2766a9-9fdb-4033-bcd8-0f1e4349ca46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
