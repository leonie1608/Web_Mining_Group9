{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9404c2c-0d76-4947-b4ee-02cbbc5adc42",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "ab3b48d8-1534-41e7-8761-4b7dd8291d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the surprise package\n",
    "!pip install -q -U scikit-surprise\n",
    "from surprise import Dataset, Reader\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbff1c1f-d7bc-40ab-942a-0b78586ebc61",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38ffa0a8-4075-4bfd-b334-9ff7bde6c21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading and processing the data in chunks for large datasets or busy RAM\n",
    "def read_and_process_json_in_chunks(path, chunksize=10000, dtype=None):\n",
    "    chunks = []\n",
    "    for chunk in pd.read_json(path, lines=True, dtype=dtype, chunksize=chunksize):\n",
    "        chunks.append(chunk)\n",
    "    return pd.concat(chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8defbc8b-c08f-428a-af19-e2b3ee2ca370",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ratings = os.path.expanduser('../data/Kindle_Store_5.json.gz')\n",
    "ratings = read_and_process_json_in_chunks(path_ratings, dtype= {'reviewerID': str, 'asin': str, 'overall': int, 'reviewTime': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6c5305d-1f8a-4c0e-b192-70216222af40",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_meta = os.path.expanduser('../data/meta_Kindle_Store.json.gz')\n",
    "meta_data = read_and_process_json_in_chunks(path_meta,  dtype= {'category': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cf126f7-e905-43b6-a57e-27714de4d336",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_ratings = ratings.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e10a54c3-0ab4-479d-88d8-3413111b6765",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_meta = meta_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b874c92-7f4d-4529-85ca-c22d1e9b643a",
   "metadata": {},
   "source": [
    "## Preprocessing Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0975aa31-c2a6-40ed-b56c-3ffafad6fd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the name of the ratings column from overall to rating to make this more clear\n",
    "preprocessing_ratings.rename(columns={'overall':'rating'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11592a92-95e7-459b-9713-fbf364ee93b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Duplicate Rating entries\n",
    "preprocessing_ratings.drop_duplicates(subset=['reviewerID', 'asin'], keep='first', inplace=True, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6140cbca-2fc2-43c9-9d19-0f779fe56487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out every style except Kindle (Paperback, Audible, Hardcover, MP3 CD remove)\n",
    "if 'style' in preprocessing_ratings.columns:\n",
    "    # Filter the DataFrame to include only rows where 'style' column contains only Kindle\n",
    "    preprocessing_ratings = preprocessing_ratings[preprocessing_ratings['style'].astype(str).str.contains(\"{'Format:': ' Kindle Edition'}\")]\n",
    "    # Remove verified column, as we assume, all remaining ratings are for Products within the Kindle Edition\n",
    "    preprocessing_ratings = preprocessing_ratings.drop(columns=['style'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ba0b246-baee-4f26-89a2-054a16c99741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by verified and remove unverified reviews\n",
    "if 'verified' in preprocessing_ratings.columns:\n",
    "    preprocessing_ratings = preprocessing_ratings[preprocessing_ratings['verified'] == True]\n",
    "    # Remove verified column, as we assume, all remaining ratings are verified\n",
    "    preprocessing_ratings.drop(columns=['verified'], inplace=True)\n",
    "\n",
    "# Drop unixReviewTime\n",
    "if 'unixReviewTime' in preprocessing_ratings.columns:\n",
    "    preprocessing_ratings.drop(columns=['unixReviewTime'], inplace=True)\n",
    "\n",
    "# Drop unixReviewTime\n",
    "if 'reviewTime' in preprocessing_ratings.columns:\n",
    "    preprocessing_ratings.drop(columns=['reviewTime'], inplace=True)\n",
    "\n",
    "# Drop the 'image' column\n",
    "if 'image' in preprocessing_ratings.columns:\n",
    "    preprocessing_ratings = preprocessing_ratings.drop(columns=['image'])\n",
    "\n",
    "# Drop the 'reviewText' column\n",
    "if 'reviewText' in preprocessing_ratings.columns:\n",
    "    preprocessing_ratings = preprocessing_ratings.drop(columns=['reviewText'])\n",
    "\n",
    "# Drop the 'summary' column\n",
    "if 'summary' in preprocessing_ratings.columns:\n",
    "    preprocessing_ratings = preprocessing_ratings.drop(columns=['summary'])\n",
    "\n",
    "# Drop the 'reviewerName' column\n",
    "if 'reviewerName' in preprocessing_ratings.columns:\n",
    "    preprocessing_ratings = preprocessing_ratings.drop(columns=['reviewerName'])\n",
    "\n",
    "# Drop the 'vote' column\n",
    "if 'vote' in preprocessing_ratings.columns:\n",
    "    preprocessing_ratings = preprocessing_ratings.drop(columns=['vote'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a5638d2-e4a2-4e16-b240-f54204599490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>A2LSKD2H9U8N0J</td>\n",
       "      <td>B000FA5KK0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>A2QP13XTJND1QS</td>\n",
       "      <td>B000FA5KK0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>A8WQ7MAG3HFOZ</td>\n",
       "      <td>B000FA5KK0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>A1E0MODSRYP7O</td>\n",
       "      <td>B000FA5KK0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>AYUTCGVSM1H7T</td>\n",
       "      <td>B000FA5KK0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating      reviewerID        asin\n",
       "0       4  A2LSKD2H9U8N0J  B000FA5KK0\n",
       "1       5  A2QP13XTJND1QS  B000FA5KK0\n",
       "2       5   A8WQ7MAG3HFOZ  B000FA5KK0\n",
       "3       5   A1E0MODSRYP7O  B000FA5KK0\n",
       "4       5   AYUTCGVSM1H7T  B000FA5KK0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5d3109-9b00-4492-b6bc-5f93f224ff9e",
   "metadata": {},
   "source": [
    "## Preprocessing Meta Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd6fe7fa-8f2d-4681-a5f7-e246798fae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Duplicate Rating entries\n",
    "preprocessing_meta.drop_duplicates(subset=['title', 'asin'], keep='first', inplace=True, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69a343ad-adce-445c-a693-e86be7f8d25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '&#39;' with '&' and delete rows where 'title' is an empty string, as this is necessary for the content-based filtering\n",
    "preprocessing_meta['title'] = preprocessing_meta['title'].str.replace('&#39;', '&')\n",
    "preprocessing_meta['title'] = preprocessing_meta['title'].str.replace('&amp;', '&')\n",
    "preprocessing_meta['title'] = preprocessing_meta['title'].str.replace('&s;', \"'s\")\n",
    "preprocessing_meta = preprocessing_meta[preprocessing_meta['title'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5edbd598-cddd-4605-80b7-827d894efd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Extract the book language, print length and Publication year and turn it in a new column each\n",
    "if 'details' in preprocessing_meta.columns:\n",
    "\n",
    "    # Add the Languages of single books to a new column\n",
    "    languages = []\n",
    "    for index, row in preprocessing_meta.iterrows():\n",
    "        # Extract the 'Language' value from the 'details' dictionary\n",
    "        language = row['details'].get('Language:', None)\n",
    "        # Append the extracted value to the 'languages' list\n",
    "        languages.append(language)\n",
    "    \n",
    "    # Add the 'languages' list as a new column 'Language' to the DataFrame\n",
    "    preprocessing_meta['language'] = languages\n",
    "\n",
    "    \n",
    "    # Create an empty list to store extracted print lengths\n",
    "    print_lengths = []\n",
    "    \n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in preprocessing_meta.iterrows():\n",
    "        # Extract the 'Print Length' value from the 'details' dictionary\n",
    "        print_length_str = row['details'].get('Print Length:', None)\n",
    "        # Extracting only the numeric part from the string\n",
    "        if print_length_str:\n",
    "            print_length = ''.join(filter(str.isdigit, print_length_str))\n",
    "        else:\n",
    "            print_length = None\n",
    "        # Convert the extracted value to an integer\n",
    "        if print_length:\n",
    "            try:\n",
    "                print_length = int(print_length)\n",
    "            except ValueError:\n",
    "                print_length = None  # Handle non-finite values\n",
    "        # Append the extracted value to the 'print_lengths' list\n",
    "        print_lengths.append(print_length)\n",
    "    \n",
    "    # Add the 'print_lengths' list as a new column 'Print_Length' to the DataFrame\n",
    "    preprocessing_meta['print_length'] = print_lengths\n",
    "    \n",
    "    # Convert the 'Print_Length' column to integers, handling non-finite values\n",
    "    preprocessing_meta['print_length'] = preprocessing_meta['print_length'].astype('Int64')\n",
    "    \n",
    "    # Define bins and labels for categories\n",
    "    bins = [0, 300, 500, 700, 1000, float('inf')]\n",
    "    labels = ['small', 'medium', 'large', 'massive']\n",
    "    \n",
    "    # Fill NaN values with a placeholder value (-1 in this case)\n",
    "    preprocessing_meta['print_length'] = preprocessing_meta['print_length'].fillna(-1)\n",
    "    \n",
    "    # Create a new column 'Print_Length_Category' based on the bins\n",
    "    preprocessing_meta['print_length_category'] = np.digitize(preprocessing_meta['print_length'], bins=bins, right=False)\n",
    "    \n",
    "    # Map values over 1000 to 'massive'\n",
    "    preprocessing_meta['print_length_category'] = np.where(preprocessing_meta['print_length'] > 1000, len(labels), preprocessing_meta['print_length_category'])\n",
    "    \n",
    "    # Map bin indices to labels\n",
    "    preprocessing_meta['print_length_category'] = preprocessing_meta['print_length_category'].map({i: l for i, l in enumerate(labels, 1)})\n",
    "\n",
    "    #fill nan values with medium\n",
    "    preprocessing_meta['print_length_category'].fillna('medium', inplace=True)\n",
    "\n",
    "    preprocessing_meta = preprocessing_meta.drop(columns=['print_length'])\n",
    "    \n",
    "\n",
    "    # Create an empty list to store extracted publication years\n",
    "    publication_years = []\n",
    "    \n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in preprocessing_meta.iterrows():\n",
    "        # Extract the 'Publication Date' value from the 'details' dictionary\n",
    "        publication_date_str = row['details'].get('Publication Date:', None)\n",
    "        \n",
    "        # Extracting only the year part from the string\n",
    "        if publication_date_str:\n",
    "            publication_year_str = publication_date_str.split()[-1]\n",
    "            \n",
    "            # Convert the year string to an integer\n",
    "            try:\n",
    "                publication_year = publication_year_str\n",
    "            except ValueError:\n",
    "                publication_year = None  # Handle cases where conversion to int fails\n",
    "        else:\n",
    "            publication_year = None\n",
    "        \n",
    "        # Append the extracted value to the 'publication_years' list\n",
    "        publication_years.append(publication_year)\n",
    "    \n",
    "    # Add the 'publication_years' list as a new column 'publication_year' to the DataFrame\n",
    "    preprocessing_meta['publication_year'] = publication_years\n",
    "    \n",
    "    # Delete the 'details' column\n",
    "    preprocessing_meta.drop(columns=['details'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c045457-6eca-486f-905a-35647de48bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_category_string(category_string):\n",
    "    # Function to clean and extract categories from the category string\n",
    "    \n",
    "    # Use regular expression to find categories within square brackets\n",
    "    categories = re.findall(r\"'(.*?)'\", category_string)\n",
    "\n",
    "    # Join the categories with comma\n",
    "    cleaned_categories = ', '.join(categories)\n",
    "\n",
    "    # Remove </span> and everything after it\n",
    "    cleaned_categories = re.sub(r', </span>', '', cleaned_categories)\n",
    "    \n",
    "    # Remove HTML tags, keeping only the text\n",
    "    cleaned_categories = re.sub(r'<a class=\"a-link-normal\" href=\"[^\"]*\">([^<]*)</a>', r'\\1', cleaned_categories)\n",
    "    \n",
    "    return cleaned_categories\n",
    "\n",
    "preprocessing_meta['category_string'] = preprocessing_meta['category'].apply(process_category_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e4336fe-85e0-4ebe-b593-5f1364432dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unused columns\n",
    "\n",
    "if 'tech1' in preprocessing_meta.columns:\n",
    "    preprocessing_meta.drop(columns=['tech1'], inplace=True)\n",
    "\n",
    "if 'tech2' in preprocessing_meta.columns:\n",
    "    preprocessing_meta.drop(columns=['tech2'], inplace=True)\n",
    "\n",
    "if 'description' in preprocessing_meta.columns:\n",
    "    preprocessing_meta.drop(columns=['description'], inplace=True)\n",
    "\n",
    "if 'fit' in preprocessing_meta.columns:\n",
    "    preprocessing_meta.drop(columns=['fit'], inplace=True)\n",
    "\n",
    "if 'feature' in preprocessing_meta.columns:\n",
    "    preprocessing_meta.drop(columns=['feature'], inplace=True)\n",
    "\n",
    "if 'main_cat' in preprocessing_meta.columns:\n",
    "    preprocessing_meta.drop(columns=['main_cat'], inplace=True)\n",
    "\n",
    "if 'similar_item' in preprocessing_meta.columns:\n",
    "    preprocessing_meta.drop(columns=['similar_item'], inplace=True)\n",
    "\n",
    "if 'imageURL' in preprocessing_meta.columns:\n",
    "    preprocessing_meta.drop(columns=['imageURL'], inplace=True)\n",
    "\n",
    "if 'imageURLHighRes' in preprocessing_meta.columns:\n",
    "    preprocessing_meta.drop(columns=['imageURLHighRes'], inplace=True)\n",
    "\n",
    "if 'also_buy' in preprocessing_meta.columns:\n",
    "    preprocessing_meta.drop(columns=['also_buy'], inplace=True)\n",
    "\n",
    "if 'also_view' in preprocessing_meta.columns:\n",
    "    preprocessing_meta.drop(columns=['also_view'], inplace=True)\n",
    "\n",
    "if 'date' in preprocessing_meta.columns:\n",
    "    preprocessing_meta.drop(columns=['date'], inplace=True)\n",
    "\n",
    "if 'price' in preprocessing_meta.columns:\n",
    "    preprocessing_meta.drop(columns=['price'], inplace=True)\n",
    "\n",
    "if 'category' in preprocessing_meta.columns:\n",
    "    #delete original category columns\n",
    "    preprocessing_meta = preprocessing_meta.drop(columns=['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0034a900-08df-4b23-b8de-74a2f8e6796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column paid_free and drop the 'rank' column\n",
    "if 'rank' in preprocessing_meta.columns:\n",
    "\n",
    "    # Create a new column 'paid_free'\n",
    "    preprocessing_meta['paid_free'] = preprocessing_meta['rank'].apply(lambda x: 'Paid' if 'Paid' in str(x) else 'Free')\n",
    "\n",
    "    # Drop the 'rank' column\n",
    "    preprocessing_meta.drop(columns=['rank'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "be7da5c1-4fc6-4c11-8ae0-c72173e542fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprare the textfield 'book_info' for content-based models, as we don't have product description\n",
    "preprocessing_meta[\"book_info\"] =  preprocessing_meta['category_string'] + '  ' + preprocessing_meta['brand'] + '  ' + preprocessing_meta['paid_free']+ ' ' + preprocessing_meta['print_length_category'] + ' ' + preprocessing_meta['publication_year'] + '  ' + preprocessing_meta['language'] \n",
    "\n",
    "# Print count of nan\n",
    "nan_count = preprocessing_meta[\"book_info\"].isna().sum()\n",
    "print(f'The number of NaN values in \"book_info\" column: {nan_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a47589-d7e2-414e-9cf9-bf3dc3c61916",
   "metadata": {},
   "source": [
    "## Merge Data\n",
    "Finally the ratings and meta data are merged to have on consistent dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "13a8f3f3-66a2-458d-8700-bd70d454d747",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(preprocessing_ratings, preprocessing_meta, how=\"inner\", on=[\"asin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "303634dd-05fa-431f-a9a6-8f71ea56c4e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1361844"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "5e9d7478-be39-46ff-98a7-9b24fdfcc58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 330000  # Adjust the sample size as needed\n",
    "data = data.sample(n=sample_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "52fea56d-031c-42b4-bb97-565eac88dd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330000"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "d4d6459a-339d-4033-b84b-b49caa29e709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust the reviewed frequency, so that recommendation is feasable. This is done by removing all book, that were reviewed less than 10 times and more than 100 times\n",
    "\n",
    "book_counts = data['asin'].value_counts()\n",
    "frequent_reviewed = book_counts[(book_counts >= 30) & (book_counts < 250)].index\n",
    "data = data[data['asin'].isin(frequent_reviewed)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "6f832e75-309f-418f-958b-4164c00b2e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46771"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "1b4bf5b1-2906-4405-95f3-52255a11f8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1011\n",
      "30100\n"
     ]
    }
   ],
   "source": [
    "# Get the unique count of asins\n",
    "print(data['asin'].nunique())\n",
    "\n",
    "# Get the unique count of reviewerIDs\n",
    "print(data['reviewerID'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "29b12719-01a2-43e3-9926-3c94ca241bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel(\"../data/data_kindle_preprocessed_new.xlsx\", sheet_name='Data')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "51937e88-ec2b-4d56-94a1-2ec240c57c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rating', 'reviewerID', 'asin', 'title', 'brand', 'language',\n",
       "       'print_length_category', 'publication_year', 'category_string',\n",
       "       'paid_free', 'book_info'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a66edd-7dd2-46d0-801b-7bd1c3f38332",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
