{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ad20c4e-9da8-4e94-ba55-c0a2bd69bbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Leonie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install the surprise package\n",
    "!pip install -q -U scikit-surprise\n",
    "from surprise import Dataset, Reader\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67875ffc-a745-4444-a34e-f012c3e83789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_smaller(df, df_column, threshold):\n",
    "    \"\"\"\n",
    "    Reduces the size of the input DataFrame by removing rows associated with the least frequent values in the specified column, \n",
    "    until the length of the DataFrame is less than or equal to the given threshold.\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): The input DataFrame.\n",
    "    - df_column (str): The name of the column in the DataFrame to consider for frequency analysis.\n",
    "    - threshold (int): The maximum length that the DataFrame should have after the operation.\n",
    "\n",
    "    Returns:\n",
    "    Outputs the pruned DataFrame. No Inplace.\n",
    "\n",
    "    Example:\n",
    "    ```\n",
    "    # Reduce the size of 'df' until it contains less than or equal to 100,000 rows, based on the least frequent values in the 'reviewerID' column.\n",
    "    make_smaller(df, 'reviewerID', 100000)\n",
    "    ```\n",
    "    \"\"\"\n",
    "    small_frequency = 1\n",
    "    # Make Sample Set smaller if necessary, by removing all users with the lowest number of ratings\n",
    "    while len(df) > threshold:\n",
    "        print(\"Length of DataFrame:\", len(df))\n",
    "        print(\"Threshold:\", threshold)\n",
    "\n",
    "        if small_frequency == 1:\n",
    "            # Assuming your DataFrame is named df\n",
    "            # Count occurrences of each reviewerID\n",
    "            df_counts = df[df_column].value_counts()\n",
    "            #print(\"Value Counts:\", df_counts)\n",
    "        \n",
    "            # Find the minimum count\n",
    "            min_count = df_counts.min()\n",
    "            #print(\"Minimum Count:\", min_count)\n",
    "        \n",
    "            # Filter out reviewerIDs with the least counts\n",
    "            least_df_column = df_counts[df_counts == min_count].index\n",
    "        \n",
    "            # Filter the original DataFrame to remove rows with reviewerIDs having the least counts\n",
    "            df = df[~df[df_column].isin(least_df_column)]\n",
    "\n",
    "            # Check if the length of the DataFrame is within or below the threshold\n",
    "            if len(df) <= threshold:\n",
    "                break  # Exit the loop if the length is within or below the threshold\n",
    "\n",
    "            small_frequency = 0\n",
    "\n",
    "        if small_frequency == 0:\n",
    "            # Assuming your DataFrame is named df\n",
    "            # Count occurrences of each reviewerID\n",
    "            df_counts = df[df_column].value_counts()\n",
    "            #print(\"Value Counts:\", df_counts)\n",
    "        \n",
    "            # Find the maximum count\n",
    "            max_count = df_counts.max()\n",
    "            #print(\"Maximum Count:\", max_count)\n",
    "        \n",
    "            # Filter out reviewerIDs with the most counts\n",
    "            most_df_column = df_counts[df_counts == max_count].index\n",
    "        \n",
    "            # Filter the original DataFrame to remove rows with reviewerIDs having the most counts\n",
    "            df = df[~df[df_column].isin(most_df_column)]\n",
    "\n",
    "            # Check if the length of the DataFrame is within or below the threshold\n",
    "            if len(df) <= threshold:\n",
    "                break  # Exit the loop if the length is within or below the threshold\n",
    "\n",
    "            small_frequency = 1\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aedd20c7-ff93-4168-af23-865bbf484cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_statistics(df):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculates statistics for each column in the input DataFrame to examine preprocessing steps.\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): The input DataFrame to analyze.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A DataFrame containing statistics for each column, including:\n",
    "        - Num_Values: Total number of values in the column.\n",
    "        - Num_Not_Null: Number of non-null values in the column.\n",
    "        - Highest_Value: Highest value in the column (for numeric and string columns).\n",
    "        - Lowest_Value: Lowest value in the column (for numeric and string columns).\n",
    "        - Num_Unique: Number of unique values in the column (for numeric and string columns).\n",
    "        - Percent_Not_Null: Percentage of non-null values in the column.\n",
    "        - Percent_Null: Percentage of null values in the column.\n",
    "        - Percentage_0: Percentage of occurrences of the value '0' (for binary columns).\n",
    "        - Percentage_1: Percentage of occurrences of the value '1' (for binary columns).\n",
    "\n",
    "    Example:\n",
    "    ```\n",
    "    # Calculate statistics for each column in the DataFrame 'df'\n",
    "    stats_df = column_statistics(df)\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    stats = {}\n",
    "    total_entries = len(df)\n",
    "\n",
    "    for column in df.columns:\n",
    "        column_data = df[column]\n",
    "        num_values = len(column_data)\n",
    "        num_not_null = column_data.count()\n",
    "        num_null = num_values - num_not_null\n",
    "        num_unique = None\n",
    "        highest_value = None\n",
    "        lowest_value = None\n",
    "        percentage_0 = None\n",
    "        percentage_1 = None\n",
    "\n",
    "        if pd.api.types.is_numeric_dtype(column_data):\n",
    "            highest_value = column_data.max()\n",
    "            lowest_value = column_data.min()\n",
    "            try:\n",
    "                num_unique = column_data.nunique()\n",
    "            except TypeError:\n",
    "                pass\n",
    "\n",
    "        if pd.api.types.is_string_dtype(column_data):\n",
    "            highest_value = column_data.max()\n",
    "            lowest_value = column_data.min()\n",
    "            try:\n",
    "                num_unique = column_data.nunique()\n",
    "            except TypeError:\n",
    "                pass\n",
    "\n",
    "        if num_unique == 2:\n",
    "            percentages = column_data.value_counts(normalize=True) * 100\n",
    "            percentage_0 = percentages.get(0, 0)\n",
    "            percentage_1 = percentages.get(1, 0)\n",
    "\n",
    "        stats[column] = {\n",
    "            'Num_Values': num_values,\n",
    "            'Num_Not_Null': num_not_null,\n",
    "            'Highest_Value': highest_value,\n",
    "            'Lowest_Value': lowest_value,\n",
    "            'Num_Unique': num_unique,\n",
    "            'Percent_Not_Null': (num_not_null / total_entries) * 100,\n",
    "            'Percent_Null': (num_null / total_entries) * 100,\n",
    "            'Percentage_0': percentage_0,\n",
    "            'Percentage_1': percentage_1\n",
    "        }\n",
    "\n",
    "    return pd.DataFrame(stats).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a397d915-597b-4367-8047-73de79de561a",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load Data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/Kindle_Store_5.json.gz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m ratings \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreviewerID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43masin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moverall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreviewTime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/meta_Kindle_Store.json.gz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m meta_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_json(path, lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mstr\u001b[39m})\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\pandas\\io\\json\\_json.py:760\u001b[0m, in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_axes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m orient \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    758\u001b[0m     convert_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 760\u001b[0m json_reader \u001b[38;5;241m=\u001b[39m \u001b[43mJsonReader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    761\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    762\u001b[0m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    763\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    764\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    765\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    766\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    767\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_default_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecise_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize:\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\pandas\\io\\json\\_json.py:862\u001b[0m, in \u001b[0;36mJsonReader.__init__\u001b[1;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors, dtype_backend, engine)\u001b[0m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mujson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    861\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data_from_filepath(filepath_or_buffer)\n\u001b[1;32m--> 862\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_preprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\pandas\\io\\json\\_json.py:874\u001b[0m, in \u001b[0;36mJsonReader._preprocess_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunksize \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnrows):\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 874\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunksize \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnrows):\n\u001b[0;32m    876\u001b[0m     data \u001b[38;5;241m=\u001b[39m StringIO(data)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\gzip.py:292\u001b[0m, in \u001b[0;36mGzipFile.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01merrno\u001b[39;00m\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(errno\u001b[38;5;241m.\u001b[39mEBADF, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread() on write-only GzipFile object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 292\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\gzip.py:487\u001b[0m, in \u001b[0;36m_GzipReader.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# Read a chunk of data from the file\u001b[39;00m\n\u001b[0;32m    485\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread(io\u001b[38;5;241m.\u001b[39mDEFAULT_BUFFER_SIZE)\n\u001b[1;32m--> 487\u001b[0m uncompress \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decompressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39munconsumed_tail \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mprepend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39munconsumed_tail)\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "path = os.path.expanduser('../data/Kindle_Store_5.json.gz')\n",
    "ratings = pd.read_json(path, lines=True, dtype= {'reviewerID': str, 'asin': str, 'overall': str, 'reviewTime': str})\n",
    "\n",
    "path = os.path.expanduser('../data/meta_Kindle_Store.json.gz')\n",
    "meta_data = pd.read_json(path, lines=True, dtype= {'category': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e08e92d-ec29-4efe-bada-522178d3723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_ratings = ratings.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba777187-d015-4daa-b481-ae7a272a550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_meta = meta_data.copy()\n",
    "preprocessing_meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e04660f-372d-4fb3-a9ac-ede171b85916",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis before prerpocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bcd5811-2e60-4810-801d-0cac5f13fe8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num_Values</th>\n",
       "      <th>Num_Not_Null</th>\n",
       "      <th>Highest_Value</th>\n",
       "      <th>Lowest_Value</th>\n",
       "      <th>Num_Unique</th>\n",
       "      <th>Percent_Not_Null</th>\n",
       "      <th>Percent_Null</th>\n",
       "      <th>Percentage_0</th>\n",
       "      <th>Percentage_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <td>2222983</td>\n",
       "      <td>2222983</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verified</th>\n",
       "      <td>2222983</td>\n",
       "      <td>2222983</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.789827</td>\n",
       "      <td>36.210173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewTime</th>\n",
       "      <td>2222983</td>\n",
       "      <td>2222983</td>\n",
       "      <td>12 9, 2017</td>\n",
       "      <td>01 1, 2007</td>\n",
       "      <td>4838</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewerID</th>\n",
       "      <td>2222983</td>\n",
       "      <td>2222983</td>\n",
       "      <td>AZZXPMZMAWYZC</td>\n",
       "      <td>A0020356UF96ZV361ST</td>\n",
       "      <td>139824</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asin</th>\n",
       "      <td>2222983</td>\n",
       "      <td>2222983</td>\n",
       "      <td>B01HJENY3Y</td>\n",
       "      <td>B000FA5KK0</td>\n",
       "      <td>98824</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>style</th>\n",
       "      <td>2222983.0</td>\n",
       "      <td>2170366.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.633045</td>\n",
       "      <td>2.366955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewerName</th>\n",
       "      <td>2222983.0</td>\n",
       "      <td>2222856.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.994287</td>\n",
       "      <td>0.005713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewText</th>\n",
       "      <td>2222983.0</td>\n",
       "      <td>2222580.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.981871</td>\n",
       "      <td>0.018129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>2222983.0</td>\n",
       "      <td>2221228.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.921052</td>\n",
       "      <td>0.078948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unixReviewTime</th>\n",
       "      <td>2222983.0</td>\n",
       "      <td>2222983.0</td>\n",
       "      <td>1538524800.0</td>\n",
       "      <td>882057600.0</td>\n",
       "      <td>4838.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vote</th>\n",
       "      <td>2222983.0</td>\n",
       "      <td>291951.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.133299</td>\n",
       "      <td>86.866701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image</th>\n",
       "      <td>2222983.0</td>\n",
       "      <td>1365.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.061404</td>\n",
       "      <td>99.938596</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Num_Values Num_Not_Null  Highest_Value         Lowest_Value  \\\n",
       "overall           2222983      2222983            5.0                  1.0   \n",
       "verified          2222983      2222983           True                False   \n",
       "reviewTime        2222983      2222983     12 9, 2017           01 1, 2007   \n",
       "reviewerID        2222983      2222983  AZZXPMZMAWYZC  A0020356UF96ZV361ST   \n",
       "asin              2222983      2222983     B01HJENY3Y           B000FA5KK0   \n",
       "style           2222983.0    2170366.0            NaN                  NaN   \n",
       "reviewerName    2222983.0    2222856.0            NaN                  NaN   \n",
       "reviewText      2222983.0    2222580.0            NaN                  NaN   \n",
       "summary         2222983.0    2221228.0            NaN                  NaN   \n",
       "unixReviewTime  2222983.0    2222983.0   1538524800.0          882057600.0   \n",
       "vote            2222983.0     291951.0            NaN                  NaN   \n",
       "image           2222983.0       1365.0            NaN                  NaN   \n",
       "\n",
       "               Num_Unique Percent_Not_Null Percent_Null Percentage_0  \\\n",
       "overall                 5            100.0          0.0         None   \n",
       "verified                2            100.0          0.0    63.789827   \n",
       "reviewTime           4838            100.0          0.0         None   \n",
       "reviewerID         139824            100.0          0.0         None   \n",
       "asin                98824            100.0          0.0         None   \n",
       "style                 NaN        97.633045     2.366955          NaN   \n",
       "reviewerName          NaN        99.994287     0.005713          NaN   \n",
       "reviewText            NaN        99.981871     0.018129          NaN   \n",
       "summary               NaN        99.921052     0.078948          NaN   \n",
       "unixReviewTime     4838.0            100.0          0.0          NaN   \n",
       "vote                  NaN        13.133299    86.866701          NaN   \n",
       "image                 NaN         0.061404    99.938596          NaN   \n",
       "\n",
       "               Percentage_1  \n",
       "overall                None  \n",
       "verified          36.210173  \n",
       "reviewTime             None  \n",
       "reviewerID             None  \n",
       "asin                   None  \n",
       "style                   NaN  \n",
       "reviewerName            NaN  \n",
       "reviewText              NaN  \n",
       "summary                 NaN  \n",
       "unixReviewTime          NaN  \n",
       "vote                    NaN  \n",
       "image                   NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usage of statistics method\n",
    "stats_df = column_statistics(preprocessing_ratings)\n",
    "stats_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b79bfdbe-b8b4-4ddf-8217-d7149e39bcd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num_Values</th>\n",
       "      <th>Num_Not_Null</th>\n",
       "      <th>Highest_Value</th>\n",
       "      <th>Lowest_Value</th>\n",
       "      <th>Num_Unique</th>\n",
       "      <th>Percent_Not_Null</th>\n",
       "      <th>Percent_Null</th>\n",
       "      <th>Percentage_0</th>\n",
       "      <th>Percentage_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>491670</td>\n",
       "      <td>491670</td>\n",
       "      <td>['Kindle Store', 'Kindle eBooks']</td>\n",
       "      <td>['Kindle Store', 'Kindle Active Content', 'Kin...</td>\n",
       "      <td>273</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech1</th>\n",
       "      <td>491670</td>\n",
       "      <td>491670</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>491670.0</td>\n",
       "      <td>491670.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fit</th>\n",
       "      <td>491670</td>\n",
       "      <td>491670</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>491670</td>\n",
       "      <td>491670</td>\n",
       "      <td>~Sail~ (Formidable Book 1) - Kindle edition</td>\n",
       "      <td></td>\n",
       "      <td>473425</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>also_buy</th>\n",
       "      <td>491670.0</td>\n",
       "      <td>491670.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech2</th>\n",
       "      <td>491670</td>\n",
       "      <td>491670</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand</th>\n",
       "      <td>491670</td>\n",
       "      <td>491670</td>\n",
       "      <td>zuxing wang</td>\n",
       "      <td></td>\n",
       "      <td>267173</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <td>491670.0</td>\n",
       "      <td>491670.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>491670.0</td>\n",
       "      <td>491670.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>also_view</th>\n",
       "      <td>491670.0</td>\n",
       "      <td>491670.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>details</th>\n",
       "      <td>491670.0</td>\n",
       "      <td>491670.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>main_cat</th>\n",
       "      <td>491670</td>\n",
       "      <td>491670</td>\n",
       "      <td>Buy a Kindle</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.991661</td>\n",
       "      <td>0.008339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>similar_item</th>\n",
       "      <td>491670</td>\n",
       "      <td>491670</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>491670.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>491670</td>\n",
       "      <td>491670</td>\n",
       "      <td>.a-section.a-spacing-mini{margin-bottom:6px!im...</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asin</th>\n",
       "      <td>491670</td>\n",
       "      <td>491670</td>\n",
       "      <td>B01HJH8CDS</td>\n",
       "      <td>B000FA5KJQ</td>\n",
       "      <td>491670</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imageURL</th>\n",
       "      <td>491670.0</td>\n",
       "      <td>491670.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imageURLHighRes</th>\n",
       "      <td>491670.0</td>\n",
       "      <td>491670.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Num_Values Num_Not_Null  \\\n",
       "category            491670       491670   \n",
       "tech1               491670       491670   \n",
       "description       491670.0     491670.0   \n",
       "fit                 491670       491670   \n",
       "title               491670       491670   \n",
       "also_buy          491670.0     491670.0   \n",
       "tech2               491670       491670   \n",
       "brand               491670       491670   \n",
       "feature           491670.0     491670.0   \n",
       "rank              491670.0     491670.0   \n",
       "also_view         491670.0     491670.0   \n",
       "details           491670.0     491670.0   \n",
       "main_cat            491670       491670   \n",
       "similar_item        491670       491670   \n",
       "date              491670.0          0.0   \n",
       "price               491670       491670   \n",
       "asin                491670       491670   \n",
       "imageURL          491670.0     491670.0   \n",
       "imageURLHighRes   491670.0     491670.0   \n",
       "\n",
       "                                                     Highest_Value  \\\n",
       "category                         ['Kindle Store', 'Kindle eBooks']   \n",
       "tech1                                                                \n",
       "description                                                    NaN   \n",
       "fit                                                                  \n",
       "title                  ~Sail~ (Formidable Book 1) - Kindle edition   \n",
       "also_buy                                                       NaN   \n",
       "tech2                                                                \n",
       "brand                                                  zuxing wang   \n",
       "feature                                                        NaN   \n",
       "rank                                                           NaN   \n",
       "also_view                                                      NaN   \n",
       "details                                                        NaN   \n",
       "main_cat                                              Buy a Kindle   \n",
       "similar_item                                                         \n",
       "date                                                           NaN   \n",
       "price            .a-section.a-spacing-mini{margin-bottom:6px!im...   \n",
       "asin                                                    B01HJH8CDS   \n",
       "imageURL                                                       NaN   \n",
       "imageURLHighRes                                                NaN   \n",
       "\n",
       "                                                      Lowest_Value Num_Unique  \\\n",
       "category         ['Kindle Store', 'Kindle Active Content', 'Kin...        273   \n",
       "tech1                                                                       1   \n",
       "description                                                    NaN        NaN   \n",
       "fit                                                                         1   \n",
       "title                                                                  473425   \n",
       "also_buy                                                       NaN        NaN   \n",
       "tech2                                                                       1   \n",
       "brand                                                                  267173   \n",
       "feature                                                        NaN        NaN   \n",
       "rank                                                           NaN        NaN   \n",
       "also_view                                                      NaN        NaN   \n",
       "details                                                        NaN        NaN   \n",
       "main_cat                                                                    2   \n",
       "similar_item                                                                1   \n",
       "date                                                           NaN        NaN   \n",
       "price                                                                       4   \n",
       "asin                                                    B000FA5KJQ     491670   \n",
       "imageURL                                                       NaN        NaN   \n",
       "imageURLHighRes                                                NaN        NaN   \n",
       "\n",
       "                Percent_Not_Null Percent_Null Percentage_0 Percentage_1  \n",
       "category                   100.0          0.0         None         None  \n",
       "tech1                      100.0          0.0         None         None  \n",
       "description                100.0          0.0          NaN          NaN  \n",
       "fit                        100.0          0.0         None         None  \n",
       "title                      100.0          0.0         None         None  \n",
       "also_buy                   100.0          0.0          NaN          NaN  \n",
       "tech2                      100.0          0.0         None         None  \n",
       "brand                      100.0          0.0         None         None  \n",
       "feature                    100.0          0.0          NaN          NaN  \n",
       "rank                       100.0          0.0          NaN          NaN  \n",
       "also_view                  100.0          0.0          NaN          NaN  \n",
       "details                    100.0          0.0          NaN          NaN  \n",
       "main_cat                   100.0          0.0    99.991661     0.008339  \n",
       "similar_item               100.0          0.0         None         None  \n",
       "date                         0.0        100.0          NaN          NaN  \n",
       "price                      100.0          0.0         None         None  \n",
       "asin                       100.0          0.0         None         None  \n",
       "imageURL                   100.0          0.0          NaN          NaN  \n",
       "imageURLHighRes            100.0          0.0          NaN          NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usage of statistics method\n",
    "stats_df = column_statistics(preprocessing_meta)\n",
    "stats_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e602f4-d512-4f9b-911e-90518aa8c0c9",
   "metadata": {},
   "source": [
    "## Preprocessing Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0c88250-28c1-482a-9ff9-1e4d7c6c9fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the name of the ratings column from overall to rating to make this more clear\n",
    "preprocessing_ratings.rename(columns={'overall':'rating'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3cd43e6-5f01-4fa0-9a36-cdcd7bb0489b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out every style except Kindle (Paperback, Audible, Hardcover, MP3 CD remove)\n",
    "if 'style' in preprocessing_ratings.columns:\n",
    "    # Filter the DataFrame to include only rows where 'style' column contains only Kindle\n",
    "    preprocessing_ratings = preprocessing_ratings[preprocessing_ratings['style'].astype(str).str.contains(\"{'Format:': ' Kindle Edition'}\")]\n",
    "    # Remove verified column, as we assume, all remaining ratings are for Products within the Kindle Edition\n",
    "    preprocessing_ratings = preprocessing_ratings.drop(columns=['style'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8d61ea0-941d-41c3-bb9f-7ccdbf1be1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out all Ratings with null-value\n",
    "preprocessing_ratings = preprocessing_ratings[preprocessing_ratings['rating'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7d8a1d0-47f3-4b51-81bb-a012b8f34573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the 'reviewTime' column into separate columns for day, month, and year\n",
    "#not needed in the for the implemented systems\n",
    "if 'reviewTime' in preprocessing_ratings.columns:\n",
    "\n",
    "    #creating the new columns\n",
    "    #preprocessing_ratings[['day_month', 'year']] = preprocessing_ratings['reviewTime'].str.split(', ', n=1, expand=True)\n",
    "    #preprocessing_ratings[['month', 'day']] = preprocessing_ratings['day_month'].str.split(' ', n=1, expand=True)\n",
    "    \n",
    "    # Dropping the intermediate 'day_month' column\n",
    "    #preprocessing_ratings.drop(columns=['day_month'], inplace=True)\n",
    "\n",
    "    #drop the reviewTime column\n",
    "    preprocessing_ratings.drop(columns=['reviewTime'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e4c5a0b-9378-4ba3-acd9-eb2c2e310536",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete unixReviewTime\n",
    "if 'unixReviewTime' in preprocessing_ratings.columns:\n",
    "    preprocessing_ratings.drop(columns=['unixReviewTime'], inplace=True)\n",
    "\n",
    "# Drop the 'image' column\n",
    "if 'image' in preprocessing_ratings.columns:\n",
    "    preprocessing_ratings = preprocessing_ratings.drop(columns=['image'])\n",
    "\n",
    "# Filter by verified and remove unverified reviews\n",
    "if 'verified' in preprocessing_ratings.columns:\n",
    "    preprocessing_ratings = preprocessing_ratings[preprocessing_ratings['verified'] == True]\n",
    "    # Remove verified column, as we assume, all remaining ratings are verified\n",
    "    preprocessing_ratings.drop(columns=['verified'], inplace=True)\n",
    "\n",
    "# Drop the 'reviewText' column\n",
    "if 'reviewText' in preprocessing_ratings.columns:\n",
    "    preprocessing_ratings = preprocessing_ratings.drop(columns=['reviewText'])\n",
    "\n",
    "# Drop the 'summary' column\n",
    "if 'summary' in preprocessing_ratings.columns:\n",
    "    preprocessing_ratings = preprocessing_ratings.drop(columns=['summary'])\n",
    "\n",
    "# Drop the 'reviewerName' column\n",
    "if 'reviewerName' in preprocessing_ratings.columns:\n",
    "    preprocessing_ratings = preprocessing_ratings.drop(columns=['reviewerName'])\n",
    "\n",
    "# Drop the 'vote' column\n",
    "if 'vote' in preprocessing_ratings.columns:\n",
    "    preprocessing_ratings = preprocessing_ratings.drop(columns=['vote'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4edd28f8-6aff-4200-9084-e0f19bb5a063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Duplicate Rating entries\n",
    "preprocessing_ratings.drop_duplicates(subset=None, keep='first', inplace=True, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62d5d128-dc3f-4ab2-937b-6c949d983101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of DataFrame: 1369764\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 1362740\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 1347709\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 1320822\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 1268363\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 1157022\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 1069540\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 997539\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 935849\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 884281\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 839278\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 799404\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 763918\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 732187\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 700775\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 674175\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 649122\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 626954\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 605473\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 585601\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 567899\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 550352\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 533507\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 517878\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 502624\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 489235\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 475053\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 462722\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 451514\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 440443\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 428825\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 419004\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 409938\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 399718\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 390402\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 380728\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 371984\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 364191\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 355623\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 348527\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 341383\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 334383\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 327574\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 321175\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 313643\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 306263\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 300003\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 294136\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 289063\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 283647\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 277911\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 272444\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 266460\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 261066\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 255409\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 250811\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 246921\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 242172\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 238508\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 233491\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 228529\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 225064\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 220556\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 215918\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 212045\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 207857\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 204270\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 200417\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 196938\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 192360\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 188790\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 185388\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 181450\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 178400\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 176055\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 172783\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 169700\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 166735\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 163311\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 159883\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 155939\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 153410\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 150438\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 147523\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 144668\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 141358\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 138805\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 136134\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 133423\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 131842\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 129220\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 126823\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 124833\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 122453\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 120751\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 118993\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 116599\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 114575\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 111988\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 110665\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 108233\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 106355\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 104492\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 101512\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 99286\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 97378\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 95228\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 92969\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 91547\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 89797\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 87258\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 85039\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 83255\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 81475\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 79101\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 77849\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 75957\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 74806\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 73177\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 71232\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 69159\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 67771\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 66830\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 64777\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 62998\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 61586\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 60215\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 58333\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 56678\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 54929\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 52569\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 50536\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 48886\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 46773\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 45113\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 43313\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 41507\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 39593\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 38438\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 37556\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 36206\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 34664\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 33870\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 32829\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 32177\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 30764\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 29674\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 28108\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 26360\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 24758\n",
      "Threshold: 20000\n",
      "Length of DataFrame: 22704\n",
      "Threshold: 20000\n"
     ]
    }
   ],
   "source": [
    "preprocessing_ratings = make_smaller(preprocessing_ratings, 'reviewerID', 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b5ff107-00ec-4443-bbe4-a7223d9c960d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19667"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preprocessing_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9613de-9c48-4251-a6fe-ce7bec6588c0",
   "metadata": {},
   "source": [
    "## Preprocessing Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4861c1bf-c151-4abd-8a4d-fc124ff4d79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '&#39;' with '&'\n",
    "preprocessing_meta['title'] = preprocessing_meta['title'].str.replace('&#39;', '&')\n",
    "preprocessing_meta['title'] = preprocessing_meta['title'].str.replace('&amp;', '&')\n",
    "preprocessing_meta['title'] = preprocessing_meta['title'].str.replace('&s;', \"'s\")\n",
    "\n",
    "#Delete rows where 'title' is an empty string, as this is necessary for the content-based filtering\n",
    "preprocessing_meta = preprocessing_meta[preprocessing_meta['title'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59b6e029-66c3-4743-83df-ba43369376d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Extract the book language, print length and Publication year and turn it in a new column each\n",
    "if 'details' in preprocessing_meta.columns:\n",
    "\n",
    "    # Add the Languages of single books to a new column\n",
    "    languages = []\n",
    "    for index, row in preprocessing_meta.iterrows():\n",
    "        # Extract the 'Language' value from the 'details' dictionary\n",
    "        language = row['details'].get('Language:', None)\n",
    "        # Append the extracted value to the 'languages' list\n",
    "        languages.append(language)\n",
    "    \n",
    "    # Add the 'languages' list as a new column 'Language' to the DataFrame\n",
    "    preprocessing_meta['language'] = languages\n",
    "\n",
    "    \n",
    "    # Create an empty list to store extracted print lengths\n",
    "    print_lengths = []\n",
    "    \n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in preprocessing_meta.iterrows():\n",
    "        # Extract the 'Print Length' value from the 'details' dictionary\n",
    "        print_length_str = row['details'].get('Print Length:', None)\n",
    "        # Extracting only the numeric part from the string\n",
    "        if print_length_str:\n",
    "            print_length = ''.join(filter(str.isdigit, print_length_str))\n",
    "        else:\n",
    "            print_length = None\n",
    "        # Convert the extracted value to an integer\n",
    "        if print_length:\n",
    "            try:\n",
    "                print_length = int(print_length)\n",
    "            except ValueError:\n",
    "                print_length = None  # Handle non-finite values\n",
    "        # Append the extracted value to the 'print_lengths' list\n",
    "        print_lengths.append(print_length)\n",
    "    \n",
    "    # Add the 'print_lengths' list as a new column 'Print_Length' to the DataFrame\n",
    "    preprocessing_meta['print_length'] = print_lengths\n",
    "    \n",
    "    # Convert the 'Print_Length' column to integers, handling non-finite values\n",
    "    preprocessing_meta['print_length'] = preprocessing_meta['print_length'].astype('Int64')\n",
    "    \n",
    "    # Define bins and labels for categories\n",
    "    bins = [0, 300, 500, 700, 1000, float('inf')]\n",
    "    labels = ['small', 'medium', 'large', 'massive']\n",
    "    \n",
    "    # Fill NaN values with a placeholder value (-1 in this case)\n",
    "    preprocessing_meta['print_length'] = preprocessing_meta['print_length'].fillna(-1)\n",
    "    \n",
    "    # Create a new column 'Print_Length_Category' based on the bins\n",
    "    preprocessing_meta['print_length_category'] = np.digitize(preprocessing_meta['print_length'], bins=bins, right=False)\n",
    "    \n",
    "    # Map values over 1000 to 'massive'\n",
    "    preprocessing_meta['print_length_category'] = np.where(preprocessing_meta['print_length'] > 1000, len(labels), preprocessing_meta['print_length_category'])\n",
    "    \n",
    "    # Map bin indices to labels\n",
    "    preprocessing_meta['print_length_category'] = preprocessing_meta['print_length_category'].map({i: l for i, l in enumerate(labels, 1)})\n",
    "\n",
    "    #fill nan values with medium\n",
    "    preprocessing_meta['print_length_category'].fillna('medium', inplace=True)\n",
    "\n",
    "    preprocessing_meta = preprocessing_meta.drop(columns=['print_length'])\n",
    "    \n",
    "\n",
    "    # Create an empty list to store extracted publication years\n",
    "    publication_years = []\n",
    "    \n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in preprocessing_meta.iterrows():\n",
    "        # Extract the 'Publication Date' value from the 'details' dictionary\n",
    "        publication_date_str = row['details'].get('Publication Date:', None)\n",
    "        \n",
    "        # Extracting only the year part from the string\n",
    "        if publication_date_str:\n",
    "            publication_year_str = publication_date_str.split()[-1]\n",
    "            \n",
    "            # Convert the year string to an integer\n",
    "            try:\n",
    "                publication_year = publication_year_str\n",
    "            except ValueError:\n",
    "                publication_year = None  # Handle cases where conversion to int fails\n",
    "        else:\n",
    "            publication_year = None\n",
    "        \n",
    "        # Append the extracted value to the 'publication_years' list\n",
    "        publication_years.append(publication_year)\n",
    "    \n",
    "    # Add the 'publication_years' list as a new column 'publication_year' to the DataFrame\n",
    "    preprocessing_meta['publication_year'] = publication_years\n",
    "    \n",
    "    # Delete the 'details' column\n",
    "    preprocessing_meta.drop(columns=['details'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "624fa3e3-1f8c-40a8-ab25-91365cb66b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove unwanted parts using regex\n",
    "def clean_category_string(text):\n",
    "    # Remove </span> and everything after it\n",
    "    text = re.sub(r', </span>', '', text)\n",
    "    text = re.sub(r'<a class=\"a-link-normal\" href=\"[^\"]*\">([^<]*)</a>', r'\\1', text)\n",
    "    return text\n",
    "\n",
    "def extract_categories(category_string):\n",
    "    # function to extract categories as string without unneccessary token\n",
    "    # Needed for content based filtering\n",
    "    \n",
    "    # Use regular expression to find categories within square brackets\n",
    "    categories = re.findall(r\"'(.*?)'\", category_string)\n",
    "\n",
    "    # Join the categories with comma\n",
    "    return ', '.join(categories)\n",
    "\n",
    "# Apply the function to the \"category\" column\n",
    "preprocessing_meta['category_string'] = preprocessing_meta['category'].apply(extract_categories)\n",
    "\n",
    "# Apply the function to the DataFrame column\n",
    "preprocessing_meta['category_string'] = preprocessing_meta['category_string'].apply(clean_category_string)\n",
    "\n",
    "\n",
    "def category_columns(preprocessing_meta):\n",
    "    #function, that makes category into individual columns with binary values\n",
    "    #not used\n",
    "    \n",
    "    # Check if the 'category' column exists in the DataFrame\n",
    "    if 'category' in preprocessing_meta.columns:\n",
    "    \n",
    "        # remove strange entries in column categories\n",
    "        patternDel = r'(?!.*ref=).*'\n",
    "        preprocessing_meta = preprocessing_meta[~preprocessing_meta['category'].str.contains('ref=', na=False)]\n",
    "    \n",
    "        # Get unique categories\n",
    "        # Assuming preprocessing_meta is your DataFrame and 'category' is the column containing the strings\n",
    "        preprocessing_meta['category'] = preprocessing_meta['category'].str.replace('&amp; ', '&')\n",
    "        unique_categories = preprocessing_meta['category'].unique()\n",
    "        \n",
    "        # Join the unique categories into a single string\n",
    "        categories_string = ', '.join(unique_categories)\n",
    "        categories_string = categories_string.replace(\"'\", '')\n",
    "        categories_string = categories_string.replace(\"[\", '')\n",
    "        categories_string = categories_string.replace(\"]\", '')\n",
    "        \n",
    "        #print(categories_string)\n",
    "        \n",
    "        categories_list = [category.strip() for category in categories_string.split(',')]\n",
    "        categories_list_noDup = list(dict.fromkeys(categories_list))\n",
    "        categories_list_done = [category for category in categories_list_noDup if 'href' not in category]\n",
    "        categories_list_done2 = [category for category in categories_list_done if '</span>' not in category]\n",
    "        \n",
    "        for category in categories_list_done2:\n",
    "            preprocessing_meta[category] = None\n",
    "        \n",
    "        # Create columns based on categories_list_done2\n",
    "        for category in categories_list_done2:\n",
    "            preprocessing_meta[category] = preprocessing_meta['category'].apply(lambda x: 1 if category in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "257c3c6a-2355-446f-9903-7880ed26497a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         ['Kindle Store', 'Kindle eBooks', 'Science Fic...\n",
       "1         ['Kindle Store', 'Kindle eBooks', 'Engineering...\n",
       "2         ['Kindle Store', 'Kindle eBooks', 'Biographies...\n",
       "3         ['Kindle Store', 'Kindle eBooks', 'Science Fic...\n",
       "4         ['Kindle Store', 'Kindle eBooks', 'Business & ...\n",
       "                                ...                        \n",
       "491665    ['Kindle Store', 'Kindle eBooks', 'Science Fic...\n",
       "491666    ['Kindle Store', 'Kindle eBooks', 'Literature ...\n",
       "491667    ['Kindle Store', 'Kindle eBooks', 'Religion & ...\n",
       "491668    ['Kindle Store', 'Kindle eBooks', 'Literature ...\n",
       "491669    ['Kindle Store', 'Kindle eBooks', 'Literature ...\n",
       "Name: category, Length: 491670, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_meta['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98eb40b6-8d0b-4a59-a7e9-b5d445898feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unused columns\n",
    "\n",
    "if 'tech1' in preprocessing_meta.columns:\n",
    "    preprocessing_meta.drop(columns=['tech1'], inplace=True)\n",
    "\n",
    "if 'tech2' in preprocessing_meta.columns:\n",
    "    preprocessing_meta.drop(columns=['tech2'], inplace=True)\n",
    "\n",
    "if 'description' in preprocessing_meta.columns:\n",
    "    preprocessing_meta.drop(columns=['description'], inplace=True)\n",
    "\n",
    "if 'fit' in preprocessing_meta.columns:\n",
    "    preprocessing_meta.drop(columns=['fit'], inplace=True)\n",
    "\n",
    "if 'feature' in preprocessing_meta.columns:\n",
    "    preprocessing_meta.drop(columns=['feature'], inplace=True)\n",
    "\n",
    "if 'main_cat' in preprocessing_meta.columns:\n",
    "    preprocessing_meta.drop(columns=['main_cat'], inplace=True)\n",
    "\n",
    "if 'similar_item' in preprocessing_meta.columns:\n",
    "    preprocessing_meta.drop(columns=['similar_item'], inplace=True)\n",
    "\n",
    "if 'imageURL' in preprocessing_meta.columns:\n",
    "    preprocessing_meta.drop(columns=['imageURL'], inplace=True)\n",
    "\n",
    "if 'imageURLHighRes' in preprocessing_meta.columns:\n",
    "    preprocessing_meta.drop(columns=['imageURLHighRes'], inplace=True)\n",
    "\n",
    "if 'also_buy' in preprocessing_meta.columns:\n",
    "    preprocessing_meta.drop(columns=['also_buy'], inplace=True)\n",
    "\n",
    "if 'also_view' in preprocessing_meta.columns:\n",
    "    preprocessing_meta.drop(columns=['also_view'], inplace=True)\n",
    "\n",
    "if 'date' in preprocessing_meta.columns:\n",
    "    preprocessing_meta.drop(columns=['date'], inplace=True)\n",
    "\n",
    "if 'price' in preprocessing_meta.columns:\n",
    "    preprocessing_meta.drop(columns=['price'], inplace=True)\n",
    "\n",
    "#if 'category' in preprocessing_meta.columns:\n",
    "    #preprocessing_meta.drop(columns=['category'], inplace=True)\n",
    "\n",
    "# Drop the 'brand' column -> Let it there for content based\n",
    "#if 'brand' in preprocessing_meta.columns:\n",
    "#    preprocessing_meta = preprocessing_meta.drop(columns=['brand'])\n",
    "\n",
    "# Drop the 'rank' column\n",
    "if 'rank' in preprocessing_meta.columns:\n",
    "\n",
    "    # Create a new column 'paid_free'\n",
    "    preprocessing_meta['paid_free'] = preprocessing_meta['rank'].apply(lambda x: 'Paid' if 'Paid' in str(x) else 'Free')\n",
    "\n",
    "    # Drop the 'rank' column\n",
    "    preprocessing_meta.drop(columns=['rank'], inplace=True)\n",
    "    \n",
    "    # Create 'paid' column\n",
    "    #preprocessing_meta['paid'] = preprocessing_meta['rank'].str.contains('Paid', na=False, case=False).astype(int)\n",
    "    \n",
    "    # Create 'free' column\n",
    "    #preprocessing_meta['free'] = preprocessing_meta['rank'].str.contains('Free', na=False, case=False).astype(int)\n",
    "    \n",
    "    # Extracting the number from the 'rank' column using regex\n",
    "    #preprocessing_meta['rank'] = preprocessing_meta['rank'].str.extract(r'(\\d[\\d,]*)')\n",
    "    \n",
    "    # Removing commas and converting the 'rank' column to integer\n",
    "    #preprocessing_meta['rank'] = preprocessing_meta['rank'].str.replace(',', '').astype(float).astype('Int64')\n",
    "    \n",
    "if 'category' in preprocessing_meta.columns:\n",
    "    #delete original category columns\n",
    "    preprocessing_meta = preprocessing_meta.drop(columns=['category'])\n",
    "\n",
    "# Drop the 'Kindle Store' column, as it was created during category creation, but as almost eyery book has a 1, its has not much meaning\n",
    "if 'Kindle Store' in preprocessing_meta.columns:\n",
    "    preprocessing_meta = preprocessing_meta.drop(columns=['Kindle Store'])\n",
    "\n",
    "# Drop the 'Kindle eBooks' column, as it was created during category creation, but as almost eyery book has a 1, its has not much meaning\n",
    "if 'Kindle eBooks' in preprocessing_meta.columns:\n",
    "    preprocessing_meta = preprocessing_meta.drop(columns=['Kindle eBooks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f1180c0-ffe6-4644-9caa-b91af3abdea2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of NaN values in \"book_info\" column: 0\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    # lowercasing\n",
    "    lowercased_text = text.lower()\n",
    "\n",
    "    # cleaning \n",
    "    import re \n",
    "    remove_punctuation = re.sub(r'[^\\w\\s]', '', lowercased_text)\n",
    "    remove_white_space = remove_punctuation.strip()\n",
    "\n",
    "    # Tokenization = Breaking down each sentence into an array\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    tokenized_text = word_tokenize(remove_white_space)\n",
    "\n",
    "    # Stop Words/filtering = Removing irrelevant words\n",
    "    from nltk.corpus import stopwords\n",
    "    stopwords = set(stopwords.words('english'))\n",
    "    stopwords_removed = [word for word in tokenized_text if word not in stopwords]\n",
    "\n",
    "    # Stemming = Transforming words into their base form\n",
    "    from nltk.stem import PorterStemmer\n",
    "    ps = PorterStemmer()\n",
    "    stemmed_text = [ps.stem(word) for word in stopwords_removed]\n",
    "    \n",
    "    return stemmed_text  # Return only the stemmed text\n",
    "\n",
    "\n",
    "#preprare the textfield 'book_info' for content-based models, as we don't have product description\n",
    "preprocessing_meta[\"book_info\"] =  preprocessing_meta['category_string'] + '  ' + preprocessing_meta['brand'] + '  ' + preprocessing_meta['paid_free']+ ' ' + preprocessing_meta['print_length_category'] + ' ' + preprocessing_meta['publication_year'] + '  ' + preprocessing_meta['language'] \n",
    "\n",
    "# Print count of nan\n",
    "nan_count = preprocessing_meta[\"book_info\"].isna().sum()\n",
    "print(f'The number of NaN values in \"book_info\" column: {nan_count}')\n",
    "\n",
    "# delete all these nan values - important for model\n",
    "preprocessing_meta = preprocessing_meta.dropna(subset=[\"book_info\"])\n",
    "\n",
    "# Apply preprocess_text function to book_info\n",
    "preprocessing_meta['book_info'] = preprocessing_meta['book_info'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe97bed6-43f6-496f-9fe2-3be51a619084",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_meta['book_info'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad845fd-c67e-4f97-943e-31dbd917907c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(preprocessing_ratings, preprocessing_meta, on=\"asin\", how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a969cc3-63d7-4bfd-871a-f19475906cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel(\"../data/data_kindle_preprocessed.xlsx\", sheet_name='Data')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e532ba7-a6a7-43eb-8797-ff503b9c0576",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis after Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f0ad6e-6933-4253-bffa-746164b0a64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage of statistics method\n",
    "stats_df = column_statistics(data)\n",
    "stats_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466682f7-eba1-4fd3-93aa-96c1b4b06d24",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7920eaa0-b66a-495f-a5c7-a6c996da26d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by reviewerID and counting the number of ratings\n",
    "user_ratings_count = preprocessing_ratings.groupby('reviewerID').size().sort_values(ascending=False)\n",
    "\n",
    "# Counting the occurrences of each rating\n",
    "rating_counts = preprocessing_ratings['rating'].value_counts().sort_index().sort_values(ascending=False)\n",
    "\n",
    "# Counting the users with the same rated ebooks\n",
    "user_counts = user_ratings_count.value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c906666-b5c6-4477-b35a-b7c3d98ef12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e25c5e6-821c-47cf-a85a-fc311e9d4b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(user_ratings_count, bins=60, color='orange', edgecolor='orange', alpha=0.7)\n",
    "plt.title('Number of Ratings per User')\n",
    "plt.xlabel('Number of Ratings')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.yticks(range(0, 13, 2))  # Set y-axis ticks from 0 to 12 with interval of 2\n",
    "plt.xticks(range(100, 221, 20))  # Set x-axis ticks from 0 to 200 with interval of 20\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068253d7-358b-4906-a5b5-532fc5d5b34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(user_ratings_count, bins=60, color='orange', edgecolor='orange', alpha=0.7)\n",
    "plt.title('Number of Ratings per User')\n",
    "plt.xlabel('Number of Ratings')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.yticks(range(0, 13, 2))  # Set y-axis ticks from 0 to 12 with interval of 2\n",
    "plt.xticks(range(0, 221, 20))  # Set x-axis ticks from 0 to 200 with interval of 20\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81421226-362f-49aa-870e-4034f08f9771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the bar chart for distribution of overall ratings\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(rating_counts.index, rating_counts.values, color='orange', edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribution of Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Number of Ratings')\n",
    "plt.grid(True)\n",
    "plt.xticks(rating_counts.index)\n",
    "#plt.yticks(range(0, max(rating_counts) + 1, 5000))\n",
    "plt.yticks(range(0, 15000, 2000))  # Set y-axis ticks from 0 to 12 with interval of 2\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18b3395-1489-4b8b-be4a-0a1ffedc6452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the style of seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create a figure and axis object\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot a box plot of rating counts per user\n",
    "sns.boxplot(x=user_ratings_count.values, color='orange', ax=ax)\n",
    "\n",
    "# Set x-axis scale to logarithmic\n",
    "#ax.set_xscale('log')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Box Plot of Rating Counts per User')\n",
    "plt.xlabel('Number of Ratings per User')\n",
    "\n",
    "# Remove top and right spines\n",
    "sns.despine()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c723414-3fce-40c7-a286-1d67836e3b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_reviewer_ids = data['reviewerID'].unique()\n",
    "num_unique_reviewers = len(unique_reviewer_ids)\n",
    "print(\"Number of unique reviewer IDs:\", num_unique_reviewers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd43553-4fe4-4d49-bd4e-e8e27baf59c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ebooks = data['asin'].unique()\n",
    "num_unique_ebooks = len(unique_ebooks)\n",
    "print(\"Number of unique eBooks:\", num_unique_ebooks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
